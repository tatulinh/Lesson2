{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da565246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "error",
     "timestamp": 1751873937258,
     "user": {
      "displayName": "Linh Tạ Tú",
      "userId": "12352920304770350698"
     },
     "user_tz": -420
    },
    "id": "da565246",
    "outputId": "f9b7faca-0b4a-4a73-90d8-e5b762dedc2e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2-2369192365.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select top 5 * from df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic.csv'"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df.head(5) # select top 5 * from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KI0PshFg0pkv",
   "metadata": {
    "id": "KI0PshFg0pkv"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3bff8",
   "metadata": {
    "id": "efa3bff8"
   },
   "outputs": [],
   "source": [
    "# duplicate passenger // survive: song sot // sibsp, parch: hanh ly, ng di theo, embarked: cang khoi hanh, pclass: hang ve\n",
    "\n",
    "df.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb59c7",
   "metadata": {
    "id": "6ffb59c7"
   },
   "source": [
    "Khao sat du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7b823",
   "metadata": {
    "id": "51d7b823"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efc6b9",
   "metadata": {
    "id": "75efc6b9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed3a7b",
   "metadata": {
    "id": "d3ed3a7b"
   },
   "outputs": [],
   "source": [
    "# age : float vi cot nay co gia tri null\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "# xem ty le null\n",
    "\n",
    "df.isna().sum() * 100 / len(df)\n",
    "\n",
    "# bo carbin, embarked: dien gtri lon nhat, age: phan nho tung nhom\n",
    "# fill null = mean/ median theo vung du lieu \\\\ xet theo tung cum nho co su tuong dong\n",
    "# fillnull dang time series : khong fill theo median/ trung vi ( khoang interval : trung binh || 10 gia tri nam dau nam cuoi lay trung binh)\n",
    "# du lieu theo tinh chu ky -> forward back or forward  \\\\ trung binh, trung vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f2f4c",
   "metadata": {
    "id": "024f2f4c"
   },
   "outputs": [],
   "source": [
    "# fill null Embarked\n",
    "df.Embarked.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cd8ae",
   "metadata": {
    "id": "fb0cd8ae"
   },
   "outputs": [],
   "source": [
    "df.Embarked.mode()[0]      # gia tri xuat hien nhieu nhat, so ) lay gtri dau tien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853b18c",
   "metadata": {
    "id": "9853b18c"
   },
   "outputs": [],
   "source": [
    "df['Embarked'].fillna(df.Embarked.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c207be9",
   "metadata": {
    "id": "4c207be9"
   },
   "outputs": [],
   "source": [
    "# fill null cot Age\n",
    "df.Age.hist()\n",
    "\n",
    "# nen fill = median vi du lieu kp phaan phoi chuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e15fa",
   "metadata": {
    "id": "151e15fa"
   },
   "outputs": [],
   "source": [
    "df.fillna(df.Age.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cda59",
   "metadata": {
    "id": "a40cda59"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae738fb",
   "metadata": {
    "id": "9ae738fb"
   },
   "source": [
    "Thong ke du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d5da7",
   "metadata": {
    "id": "a45d5da7"
   },
   "outputs": [],
   "source": [
    "# df imbalance: chenh lech 2 nhan du lieu\n",
    "df.columns\n",
    "# survived: dau ra 0,1 => hanh khach con song hay khong , 0: song, 1: chet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105f4c7",
   "metadata": {
    "id": "d105f4c7"
   },
   "outputs": [],
   "source": [
    "# check imbalance : qtrong vi co su chenh lech, de bi bias du lieu\n",
    "df.Survived.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177879a",
   "metadata": {
    "id": "5177879a"
   },
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d3dd8",
   "metadata": {
    "id": "2b7d3dd8"
   },
   "outputs": [],
   "source": [
    "# df.corr() # chỉ hoạt động trên dữ liệu dạng số => biến đổi để dùng nhưng trong dữ liệu dạng titanic\n",
    "# này không nên dùng vì corr để phản ánh tuyến tính nên k phù hợp (cái này tăng, cái kia tăng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34416387",
   "metadata": {
    "id": "34416387"
   },
   "source": [
    "Encodeing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c917890",
   "metadata": {
    "id": "1c917890"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50c7f0",
   "metadata": {
    "id": "6f50c7f0"
   },
   "outputs": [],
   "source": [
    "# encode: sex(0,1) label encoder - phu hop voi giá trị nhị phân ;\n",
    "# sex: mapping \"female\": 0 , \"male\": 1  -- category cột để encoding\n",
    "# embrake: S, C, Q  -- khong mag tinh thứ bậc => one - hot encodeing  (pandas.get_dummy) -- category cột để encoding\n",
    "# Pclass: 0 -> 1 <=> 0 0.5 1\n",
    "# age: min max để scale về 0, 1\n",
    "# SibSp, Peach, ticket: min max, standard scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ba7eb",
   "metadata": {
    "id": "473ba7eb"
   },
   "source": [
    "minmax scaler and standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b5832",
   "metadata": {
    "id": "c50b5832"
   },
   "outputs": [],
   "source": [
    "# sex: mapping \"Female\": 0, \"Male\": 1\n",
    "# Embarked: khong co thu bac -> one hot encoding (pandas.get_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c874",
   "metadata": {
    "id": "d3e3c874"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e611b3",
   "metadata": {
    "id": "28e611b3"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ab9db",
   "metadata": {
    "id": "613ab9db"
   },
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame loaded from titanic.csv\n",
    "# --- FIX: Convert categorical data to numbers first ---\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# --- Pro Tip: Handle missing values before scaling ---\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07773a",
   "metadata": {
    "id": "be07773a"
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "# changr category - > numerical  - one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d833b",
   "metadata": {
    "id": "e45d833b"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc446c7d",
   "metadata": {
    "id": "fc446c7d"
   },
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc24a27",
   "metadata": {
    "id": "3dc24a27"
   },
   "outputs": [],
   "source": [
    "# prompt: minmax scaler and standard scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Select numerical columns for scaling (excluding 'PassengerId' and one-hot encoded 'Embarked' columns)\n",
    "numerical_cols = ['Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Sex']\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df[numerical_cols] = scaler_minmax.fit_transform(df[numerical_cols])\n",
    "print(\"DataFrame after Min-Max Scaling:\")\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
